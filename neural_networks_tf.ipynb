{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carbon Dot</th>\n",
       "      <th>Synthesis Label</th>\n",
       "      <th>6M Sulfuric Acid (mL)</th>\n",
       "      <th>Urea (grams)</th>\n",
       "      <th>Citric Acid (grams)</th>\n",
       "      <th>Positive or Negative at 365 nm excitation</th>\n",
       "      <th>Inhibition_(%)</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>OH Presence</th>\n",
       "      <th>NH Presence</th>\n",
       "      <th>SH Presence</th>\n",
       "      <th>C=O Presence</th>\n",
       "      <th>CN Presence</th>\n",
       "      <th>MaxValue (Fluorecence Ex @ 400 nm)</th>\n",
       "      <th>Emission Wavelength (Ex @ 400 nm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syn_1</td>\n",
       "      <td>B1-1</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.85976</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037919</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syn_2</td>\n",
       "      <td>B1-2</td>\n",
       "      <td>1.577</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.09150</td>\n",
       "      <td>3917.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>483.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>syn_3</td>\n",
       "      <td>B1-3</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>Both</td>\n",
       "      <td>-14.02440</td>\n",
       "      <td>667.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028918</td>\n",
       "      <td>506.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>syn_4</td>\n",
       "      <td>B1-4</td>\n",
       "      <td>1.577</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.84146</td>\n",
       "      <td>2645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>401.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>syn_5</td>\n",
       "      <td>B1-5</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.98780</td>\n",
       "      <td>971.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>401.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Carbon Dot Synthesis Label  6M Sulfuric Acid (mL)  Urea (grams)  \\\n",
       "0      syn_1            B1-1                  0.423        0.1271   \n",
       "1      syn_2            B1-2                  1.577        0.1272   \n",
       "2      syn_3            B1-3                  0.423        0.4728   \n",
       "3      syn_4            B1-4                  1.577        0.4732   \n",
       "4      syn_5            B1-5                  0.423        0.1273   \n",
       "\n",
       "   Citric Acid (grams) Positive or Negative at 365 nm excitation  \\\n",
       "0               0.1274                                       NaN   \n",
       "1               0.1274                                       NaN   \n",
       "2               0.1271                                      Both   \n",
       "3               0.1273                                       NaN   \n",
       "4               0.4734                                       NaN   \n",
       "\n",
       "   Inhibition_(%)  Conductivity  OH Presence  NH Presence  SH Presence  \\\n",
       "0        -6.85976        1768.0            1            1            0   \n",
       "1       -15.09150        3917.0            1            1            1   \n",
       "2       -14.02440         667.0            1            1            1   \n",
       "3        -8.84146        2645.0            1            1            0   \n",
       "4       -17.98780         971.0            1            1            1   \n",
       "\n",
       "   C=O Presence  CN Presence  MaxValue (Fluorecence Ex @ 400 nm)  \\\n",
       "0             1            1                            0.037919   \n",
       "1             1            1                            0.009542   \n",
       "2             1            1                            0.028918   \n",
       "3             1            1                            0.012842   \n",
       "4             1            1                            0.010605   \n",
       "\n",
       "   Emission Wavelength (Ex @ 400 nm)  \n",
       "0                              403.1  \n",
       "1                              483.1  \n",
       "2                              506.7  \n",
       "3                              401.1  \n",
       "4                              401.1  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"carbon_dot_ml_data - Data.csv\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carbon Dot</th>\n",
       "      <th>Synthesis Label</th>\n",
       "      <th>6M Sulfuric Acid (mL)</th>\n",
       "      <th>Urea (grams)</th>\n",
       "      <th>Citric Acid (grams)</th>\n",
       "      <th>Positive or Negative at 365 nm excitation</th>\n",
       "      <th>Inhibition_(%)</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>OH Presence</th>\n",
       "      <th>NH Presence</th>\n",
       "      <th>SH Presence</th>\n",
       "      <th>C=O Presence</th>\n",
       "      <th>CN Presence</th>\n",
       "      <th>MaxValue (Fluorecence Ex @ 400 nm)</th>\n",
       "      <th>Emission Wavelength (Ex @ 400 nm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>syn_18</td>\n",
       "      <td>B2-7</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.640240</td>\n",
       "      <td>1420.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>403.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>syn_22</td>\n",
       "      <td>N</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.317070</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068706</td>\n",
       "      <td>495.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>syn_11</td>\n",
       "      <td>B1-11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1663.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>401.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>syn_20</td>\n",
       "      <td>B2-9</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.079268</td>\n",
       "      <td>1582.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>404.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>syn_15</td>\n",
       "      <td>B2-4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.6001</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>Both</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>660.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>syn_21</td>\n",
       "      <td>NS</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Both</td>\n",
       "      <td>17.378050</td>\n",
       "      <td>3781.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481566</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>syn_27</td>\n",
       "      <td>ML-5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.6002</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>Both</td>\n",
       "      <td>8.231707</td>\n",
       "      <td>196.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>636.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>syn_4</td>\n",
       "      <td>B1-4</td>\n",
       "      <td>1.577</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.841460</td>\n",
       "      <td>2645.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>401.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>syn_25</td>\n",
       "      <td>ML-3</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.006100</td>\n",
       "      <td>3935.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>syn_23</td>\n",
       "      <td>ML-1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.902440</td>\n",
       "      <td>456.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.782150</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>syn_24</td>\n",
       "      <td>ML-2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.573170</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009755</td>\n",
       "      <td>403.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>syn_5</td>\n",
       "      <td>B1-5</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.987800</td>\n",
       "      <td>971.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>401.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>syn_3</td>\n",
       "      <td>B1-3</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.4728</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>Both</td>\n",
       "      <td>-14.024400</td>\n",
       "      <td>667.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028918</td>\n",
       "      <td>506.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>syn_26</td>\n",
       "      <td>ML-4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.469510</td>\n",
       "      <td>3914.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>400.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>syn_7</td>\n",
       "      <td>B1-7</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>Both</td>\n",
       "      <td>-12.195100</td>\n",
       "      <td>424.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>544.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>syn_19</td>\n",
       "      <td>B2-8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.829270</td>\n",
       "      <td>1582.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>syn_14</td>\n",
       "      <td>B2-3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.054880</td>\n",
       "      <td>3915.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>syn_8</td>\n",
       "      <td>B1-8</td>\n",
       "      <td>1.577</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.164630</td>\n",
       "      <td>1845.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>401.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>syn_28</td>\n",
       "      <td>ML-6</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.6004</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>Both</td>\n",
       "      <td>3.963415</td>\n",
       "      <td>276.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>509.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syn_2</td>\n",
       "      <td>B1-2</td>\n",
       "      <td>1.577</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.091500</td>\n",
       "      <td>3917.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>483.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>syn_17</td>\n",
       "      <td>B2-6</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.6003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.701220</td>\n",
       "      <td>1066.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syn_1</td>\n",
       "      <td>B1-1</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.859760</td>\n",
       "      <td>1768.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037919</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>syn_16</td>\n",
       "      <td>B2-5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.134150</td>\n",
       "      <td>3933.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>syn_30</td>\n",
       "      <td>ML-8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>Negative</td>\n",
       "      <td>11.280490</td>\n",
       "      <td>539.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>403.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Carbon Dot Synthesis Label  6M Sulfuric Acid (mL)  Urea (grams)  \\\n",
       "17     syn_18            B2-7                  1.000        0.3001   \n",
       "21     syn_22               N                  0.000        0.5000   \n",
       "10     syn_11           B1-11                  1.000        0.3007   \n",
       "19     syn_20            B2-9                  1.000        0.3004   \n",
       "14     syn_15            B2-4                  1.000        0.6001   \n",
       "20     syn_21              NS                  2.000        0.5000   \n",
       "26     syn_27            ML-5                  0.000        0.6002   \n",
       "3       syn_4            B1-4                  1.577        0.4732   \n",
       "24     syn_25            ML-3                  2.500        0.0000   \n",
       "22     syn_23            ML-1                  0.000        0.0000   \n",
       "23     syn_24            ML-2                  0.000        1.0002   \n",
       "4       syn_5            B1-5                  0.423        0.1273   \n",
       "2       syn_3            B1-3                  0.423        0.4728   \n",
       "25    syn_26             ML-4                  1.000        0.0000   \n",
       "6       syn_7            B1-7                  0.423        0.4730   \n",
       "18     syn_19            B2-8                  1.000        0.3001   \n",
       "13     syn_14            B2-3                  1.000        0.0000   \n",
       "7       syn_8            B1-8                  1.577        0.4732   \n",
       "27     syn_28            ML-6                  1.000        0.6004   \n",
       "1       syn_2            B1-2                  1.577        0.1272   \n",
       "16     syn_17            B2-6                  1.000        0.3007   \n",
       "0       syn_1            B1-1                  0.423        0.1271   \n",
       "15     syn_16            B2-5                  1.000        0.3001   \n",
       "29     syn_30            ML-8                  0.000        0.0000   \n",
       "\n",
       "    Citric Acid (grams) Positive or Negative at 365 nm excitation  \\\n",
       "17               0.3000                                       NaN   \n",
       "21               0.0000                                       NaN   \n",
       "10               0.3007                                       NaN   \n",
       "19               0.2999                                       NaN   \n",
       "14               0.3000                                      Both   \n",
       "20               0.0000                                      Both   \n",
       "26               0.6004                                      Both   \n",
       "3                0.1273                                       NaN   \n",
       "24               0.0000                                       NaN   \n",
       "22               0.5004                                       NaN   \n",
       "23               0.0000                                       NaN   \n",
       "4                0.4734                                       NaN   \n",
       "2                0.1271                                      Both   \n",
       "25               0.3003                                       NaN   \n",
       "6                0.4731                                      Both   \n",
       "18               0.3004                                       NaN   \n",
       "13               0.3001                                       NaN   \n",
       "7                0.4732                                       NaN   \n",
       "27               0.6007                                      Both   \n",
       "1                0.1274                                       NaN   \n",
       "16               0.6003                                       NaN   \n",
       "0                0.1274                                       NaN   \n",
       "15               0.0000                                       NaN   \n",
       "29               1.0005                                  Negative   \n",
       "\n",
       "    Inhibition_(%)  Conductivity  OH Presence  NH Presence  SH Presence  \\\n",
       "17       -5.640240       1420.00            1            1            1   \n",
       "21       57.317070         30.00            1            1            0   \n",
       "10       12.500000       1663.00            1            1            1   \n",
       "19        8.079268       1582.75            1            1            1   \n",
       "14        7.317073        660.00            1            1            0   \n",
       "20       17.378050       3781.00            1            1            1   \n",
       "26        8.231707        196.00            1            1            0   \n",
       "3        -8.841460       2645.00            1            1            0   \n",
       "24      -16.006100       3935.00            1            0            1   \n",
       "22       18.902440        456.00            1            0            0   \n",
       "23       -4.573170         15.00            1            1            0   \n",
       "4       -17.987800        971.00            1            1            1   \n",
       "2       -14.024400        667.00            1            1            1   \n",
       "25       -7.469510       3914.00            1            0            1   \n",
       "6       -12.195100        424.00            1            1            0   \n",
       "18       -1.829270       1582.75            1            1            1   \n",
       "13       19.054880       3915.00            1            0            1   \n",
       "7        -7.164630       1845.00            1            1            1   \n",
       "27        3.963415        276.00            1            1            0   \n",
       "1       -15.091500       3917.00            1            1            1   \n",
       "16       15.701220       1066.00            1            1            1   \n",
       "0        -6.859760       1768.00            1            1            0   \n",
       "15       -2.134150       3933.00            1            1            1   \n",
       "29       11.280490        539.00            1            0            1   \n",
       "\n",
       "    C=O Presence  CN Presence  MaxValue (Fluorecence Ex @ 400 nm)  \\\n",
       "17             1            1                            0.006065   \n",
       "21             1            1                            0.068706   \n",
       "10             1            1                            0.006207   \n",
       "19             1            1                            0.006863   \n",
       "14             1            1                            0.017681   \n",
       "20             1            1                            0.481566   \n",
       "26             1            1                            0.002463   \n",
       "3              1            1                            0.012842   \n",
       "24             0            0                            0.347000   \n",
       "22             1            0                            0.782150   \n",
       "23             1            1                            0.009755   \n",
       "4              1            1                            0.010605   \n",
       "2              1            1                            0.028918   \n",
       "25             1            0                            0.007290   \n",
       "6              1            1                            0.005427   \n",
       "18             1            1                            0.006206   \n",
       "13             1            0                            0.019444   \n",
       "7              1            1                            0.007918   \n",
       "27             1            1                            0.009963   \n",
       "1              1            1                            0.009542   \n",
       "16             1            1                            0.007493   \n",
       "0              1            1                            0.037919   \n",
       "15             0            1                            0.015407   \n",
       "29             1            0                            0.021100   \n",
       "\n",
       "    Emission Wavelength (Ex @ 400 nm)  \n",
       "17                              403.7  \n",
       "21                              495.5  \n",
       "10                              401.8  \n",
       "19                              404.4  \n",
       "14                              521.0  \n",
       "20                              403.1  \n",
       "26                              636.5  \n",
       "3                               401.1  \n",
       "24                              403.1  \n",
       "22                              403.1  \n",
       "23                              403.7  \n",
       "4                               401.1  \n",
       "2                               506.7  \n",
       "25                              400.5  \n",
       "6                               544.8  \n",
       "18                              403.1  \n",
       "13                              405.0  \n",
       "7                               401.8  \n",
       "27                              509.3  \n",
       "1                               483.1  \n",
       "16                              405.0  \n",
       "0                               403.1  \n",
       "15                              405.0  \n",
       "29                              403.1  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into train and validation data\n",
    "\n",
    "df_train = df.sample(frac =0.8, random_state = 1)\n",
    "\n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[['Urea (grams)', '6M Sulfuric Acid (mL)']]\n",
    "x_valid = df_valid[['Urea (grams)', '6M Sulfuric Acid (mL)']]\n",
    "y_train = df_train['Emission Wavelength (Ex @ 400 nm)']\n",
    "y_valid = df_valid['Emission Wavelength (Ex @ 400 nm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 2)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "   min_delta = 0.1,\n",
    "   patience =20,\n",
    "  restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    #layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation= 'relu', input_shape=[2]),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation = 'relu'), \n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    #layers.Dense(128, activation = 'relu'),\n",
    "    #layers.BatchNormalization(),\n",
    "    #layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'mae'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 6 samples\n",
      "Epoch 1/800\n",
      "24/24 [==============================] - 2s 71ms/sample - loss: 439.5181 - val_loss: 425.4964\n",
      "Epoch 2/800\n",
      "24/24 [==============================] - 0s 651us/sample - loss: 439.4901 - val_loss: 425.4794\n",
      "Epoch 3/800\n",
      "24/24 [==============================] - 0s 196us/sample - loss: 439.4612 - val_loss: 425.4674\n",
      "Epoch 4/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.4313 - val_loss: 425.4429\n",
      "Epoch 5/800\n",
      "24/24 [==============================] - 0s 487us/sample - loss: 439.4003 - val_loss: 425.4184\n",
      "Epoch 6/800\n",
      "24/24 [==============================] - 0s 22us/sample - loss: 439.3681 - val_loss: 425.3872\n",
      "Epoch 7/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.3346 - val_loss: 425.3596\n",
      "Epoch 8/800\n",
      "24/24 [==============================] - 0s 694us/sample - loss: 439.2999 - val_loss: 425.3297\n",
      "Epoch 9/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.2639 - val_loss: 425.3092\n",
      "Epoch 10/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.2264 - val_loss: 425.2751\n",
      "Epoch 11/800\n",
      "24/24 [==============================] - 0s 721us/sample - loss: 439.1874 - val_loss: 425.2422\n",
      "Epoch 12/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.1468 - val_loss: 425.2054\n",
      "Epoch 13/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.1047 - val_loss: 425.1762\n",
      "Epoch 14/800\n",
      "24/24 [==============================] - 0s 678us/sample - loss: 439.0608 - val_loss: 425.1399\n",
      "Epoch 15/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 439.0153 - val_loss: 425.0975\n",
      "Epoch 16/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.9680 - val_loss: 425.0486\n",
      "Epoch 17/800\n",
      "24/24 [==============================] - 0s 687us/sample - loss: 438.9188 - val_loss: 425.0064\n",
      "Epoch 18/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.8678 - val_loss: 424.9572\n",
      "Epoch 19/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.8149 - val_loss: 424.9065\n",
      "Epoch 20/800\n",
      "24/24 [==============================] - 0s 787us/sample - loss: 438.7600 - val_loss: 424.8604\n",
      "Epoch 21/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.7031 - val_loss: 424.8051\n",
      "Epoch 22/800\n",
      "24/24 [==============================] - 0s 605us/sample - loss: 438.6441 - val_loss: 424.7423\n",
      "Epoch 23/800\n",
      "24/24 [==============================] - 0s 208us/sample - loss: 438.5831 - val_loss: 424.6809\n",
      "Epoch 24/800\n",
      "24/24 [==============================] - 0s 167us/sample - loss: 438.5200 - val_loss: 424.6211\n",
      "Epoch 25/800\n",
      "24/24 [==============================] - 0s 306us/sample - loss: 438.4547 - val_loss: 424.5587\n",
      "Epoch 26/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.3872 - val_loss: 424.4984\n",
      "Epoch 27/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.3175 - val_loss: 424.4226\n",
      "Epoch 28/800\n",
      "24/24 [==============================] - 0s 704us/sample - loss: 438.2456 - val_loss: 424.3600\n",
      "Epoch 29/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 438.1714 - val_loss: 424.2890\n",
      "Epoch 30/800\n",
      "24/24 [==============================] - 0s 595us/sample - loss: 438.0949 - val_loss: 424.2250\n",
      "Epoch 31/800\n",
      "24/24 [==============================] - 0s 30us/sample - loss: 438.0161 - val_loss: 424.1580\n",
      "Epoch 32/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 437.9350 - val_loss: 424.0826\n",
      "Epoch 33/800\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 437.8515 - val_loss: 423.9974\n",
      "Epoch 34/800\n",
      "24/24 [==============================] - 0s 44us/sample - loss: 437.7655 - val_loss: 423.9218\n",
      "Epoch 35/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 437.6773 - val_loss: 423.8354\n",
      "Epoch 36/800\n",
      "24/24 [==============================] - 0s 700us/sample - loss: 437.5866 - val_loss: 423.7466\n",
      "Epoch 37/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 437.4935 - val_loss: 423.6617\n",
      "Epoch 38/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 437.3978 - val_loss: 423.5738\n",
      "Epoch 39/800\n",
      "24/24 [==============================] - 0s 658us/sample - loss: 437.2998 - val_loss: 423.4911\n",
      "Epoch 40/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 437.1992 - val_loss: 423.4005\n",
      "Epoch 41/800\n",
      "24/24 [==============================] - 0s 639us/sample - loss: 437.0962 - val_loss: 423.2926\n",
      "Epoch 42/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 436.9906 - val_loss: 423.1862\n",
      "Epoch 43/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 436.8825 - val_loss: 423.0931\n",
      "Epoch 44/800\n",
      "24/24 [==============================] - 0s 728us/sample - loss: 436.7719 - val_loss: 422.9932\n",
      "Epoch 45/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 436.6587 - val_loss: 422.8885\n",
      "Epoch 46/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 436.5430 - val_loss: 422.7762\n",
      "Epoch 47/800\n",
      "24/24 [==============================] - 0s 663us/sample - loss: 436.4247 - val_loss: 422.6694\n",
      "Epoch 48/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 436.3038 - val_loss: 422.5494\n",
      "Epoch 49/800\n",
      "24/24 [==============================] - 0s 656us/sample - loss: 436.1803 - val_loss: 422.4244\n",
      "Epoch 50/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 436.0542 - val_loss: 422.2893\n",
      "Epoch 51/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 435.9255 - val_loss: 422.1427\n",
      "Epoch 52/800\n",
      "24/24 [==============================] - 0s 698us/sample - loss: 435.7942 - val_loss: 422.0070\n",
      "Epoch 53/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 435.6603 - val_loss: 421.8751\n",
      "Epoch 54/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 435.5237 - val_loss: 421.7515\n",
      "Epoch 55/800\n",
      "24/24 [==============================] - 0s 692us/sample - loss: 435.3845 - val_loss: 421.6183\n",
      "Epoch 56/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 435.2426 - val_loss: 421.4980\n",
      "Epoch 57/800\n",
      "24/24 [==============================] - 0s 662us/sample - loss: 435.0981 - val_loss: 421.3468\n",
      "Epoch 58/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 434.9510 - val_loss: 421.2098\n",
      "Epoch 59/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 434.8011 - val_loss: 421.0704\n",
      "Epoch 60/800\n",
      "24/24 [==============================] - 0s 718us/sample - loss: 434.6486 - val_loss: 420.9161\n",
      "Epoch 61/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 434.4935 - val_loss: 420.7505\n",
      "Epoch 62/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 434.3356 - val_loss: 420.5966\n",
      "Epoch 63/800\n",
      "24/24 [==============================] - 0s 677us/sample - loss: 434.1750 - val_loss: 420.4335\n",
      "Epoch 64/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 434.0118 - val_loss: 420.2581\n",
      "Epoch 65/800\n",
      "24/24 [==============================] - 0s 651us/sample - loss: 433.8458 - val_loss: 420.0953\n",
      "Epoch 66/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 433.6772 - val_loss: 419.9333\n",
      "Epoch 67/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 433.5059 - val_loss: 419.7513\n",
      "Epoch 68/800\n",
      "24/24 [==============================] - 0s 694us/sample - loss: 433.3318 - val_loss: 419.5807\n",
      "Epoch 69/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 433.1550 - val_loss: 419.3985\n",
      "Epoch 70/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 432.9756 - val_loss: 419.2245\n",
      "Epoch 71/800\n",
      "24/24 [==============================] - 0s 765us/sample - loss: 432.7934 - val_loss: 419.0497\n",
      "Epoch 72/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 432.6084 - val_loss: 418.8622\n",
      "Epoch 73/800\n",
      "24/24 [==============================] - 0s 602us/sample - loss: 432.4208 - val_loss: 418.6529\n",
      "Epoch 74/800\n",
      "24/24 [==============================] - 0s 55us/sample - loss: 432.2304 - val_loss: 418.4702\n",
      "Epoch 75/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 432.0373 - val_loss: 418.2793\n",
      "Epoch 76/800\n",
      "24/24 [==============================] - 0s 673us/sample - loss: 431.8415 - val_loss: 418.0697\n",
      "Epoch 77/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 431.6429 - val_loss: 417.8587\n",
      "Epoch 78/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 431.4416 - val_loss: 417.6687\n",
      "Epoch 79/800\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 431.2376 - val_loss: 417.4606\n",
      "Epoch 80/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 431.0308 - val_loss: 417.2456\n",
      "Epoch 81/800\n",
      "24/24 [==============================] - 0s 657us/sample - loss: 430.8213 - val_loss: 417.0365\n",
      "Epoch 82/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 430.6091 - val_loss: 416.8332\n",
      "Epoch 83/800\n",
      "24/24 [==============================] - 0s 629us/sample - loss: 430.3940 - val_loss: 416.6247\n",
      "Epoch 84/800\n",
      "24/24 [==============================] - 0s 52us/sample - loss: 430.1763 - val_loss: 416.4135\n",
      "Epoch 85/800\n",
      "24/24 [==============================] - 0s 669us/sample - loss: 429.9558 - val_loss: 416.1694\n",
      "Epoch 86/800\n",
      "24/24 [==============================] - 0s 45us/sample - loss: 429.7326 - val_loss: 415.9536\n",
      "Epoch 87/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 429.5066 - val_loss: 415.7349\n",
      "Epoch 88/800\n",
      "24/24 [==============================] - 0s 649us/sample - loss: 429.2778 - val_loss: 415.5149\n",
      "Epoch 89/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 429.0463 - val_loss: 415.2716\n",
      "Epoch 90/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 428.8121 - val_loss: 415.0274\n",
      "Epoch 91/800\n",
      "24/24 [==============================] - 0s 131us/sample - loss: 428.5751 - val_loss: 414.8293\n",
      "Epoch 92/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 428.3354 - val_loss: 414.5963\n",
      "Epoch 93/800\n",
      "24/24 [==============================] - 0s 646us/sample - loss: 428.0928 - val_loss: 414.3393\n",
      "Epoch 94/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 427.8476 - val_loss: 414.1026\n",
      "Epoch 95/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 427.5996 - val_loss: 413.8570\n",
      "Epoch 96/800\n",
      "24/24 [==============================] - 0s 687us/sample - loss: 427.3488 - val_loss: 413.6421\n",
      "Epoch 97/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 427.0953 - val_loss: 413.3702\n",
      "Epoch 98/800\n",
      "24/24 [==============================] - 0s 620us/sample - loss: 426.8390 - val_loss: 413.1245\n",
      "Epoch 99/800\n",
      "24/24 [==============================] - 0s 41us/sample - loss: 426.5800 - val_loss: 412.8911\n",
      "Epoch 100/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 426.3182 - val_loss: 412.6069\n",
      "Epoch 101/800\n",
      "24/24 [==============================] - 0s 676us/sample - loss: 426.0537 - val_loss: 412.3572\n",
      "Epoch 102/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 425.7864 - val_loss: 412.0759\n",
      "Epoch 103/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 425.5163 - val_loss: 411.8025\n",
      "Epoch 104/800\n",
      "24/24 [==============================] - 0s 699us/sample - loss: 425.2435 - val_loss: 411.5330\n",
      "Epoch 105/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 424.9680 - val_loss: 411.2670\n",
      "Epoch 106/800\n",
      "24/24 [==============================] - 0s 617us/sample - loss: 424.6897 - val_loss: 411.0189\n",
      "Epoch 107/800\n",
      "24/24 [==============================] - 0s 66us/sample - loss: 424.4086 - val_loss: 410.7538\n",
      "Epoch 108/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 424.1248 - val_loss: 410.4706\n",
      "Epoch 109/800\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 423.8382 - val_loss: 410.1991\n",
      "Epoch 110/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 423.5489 - val_loss: 409.9572\n",
      "Epoch 111/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 423.2569 - val_loss: 409.6556\n",
      "Epoch 112/800\n",
      "24/24 [==============================] - 0s 692us/sample - loss: 422.9620 - val_loss: 409.3799\n",
      "Epoch 113/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 422.6645 - val_loss: 409.1155\n",
      "Epoch 114/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 422.3641 - val_loss: 408.7976\n",
      "Epoch 115/800\n",
      "24/24 [==============================] - 0s 81us/sample - loss: 422.0611 - val_loss: 408.4880\n",
      "Epoch 116/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 421.7553 - val_loss: 408.1480\n",
      "Epoch 117/800\n",
      "24/24 [==============================] - 0s 688us/sample - loss: 421.4467 - val_loss: 407.8198\n",
      "Epoch 118/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 421.1354 - val_loss: 407.5143\n",
      "Epoch 119/800\n",
      "24/24 [==============================] - 0s 658us/sample - loss: 420.8214 - val_loss: 407.2081\n",
      "Epoch 120/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 420.5045 - val_loss: 406.8839\n",
      "Epoch 121/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 420.1850 - val_loss: 406.5892\n",
      "Epoch 122/800\n",
      "24/24 [==============================] - 0s 728us/sample - loss: 419.8627 - val_loss: 406.2743\n",
      "Epoch 123/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 419.5377 - val_loss: 405.9575\n",
      "Epoch 124/800\n",
      "24/24 [==============================] - 0s 587us/sample - loss: 419.2099 - val_loss: 405.5922\n",
      "Epoch 125/800\n",
      "24/24 [==============================] - 0s 99us/sample - loss: 418.8794 - val_loss: 405.2550\n",
      "Epoch 126/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 418.5462 - val_loss: 404.8927\n",
      "Epoch 127/800\n",
      "24/24 [==============================] - 0s 671us/sample - loss: 418.2102 - val_loss: 404.5247\n",
      "Epoch 128/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 417.8715 - val_loss: 404.1867\n",
      "Epoch 129/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 417.5300 - val_loss: 403.8742\n",
      "Epoch 130/800\n",
      "24/24 [==============================] - 0s 693us/sample - loss: 417.1859 - val_loss: 403.5227\n",
      "Epoch 131/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 416.8389 - val_loss: 403.2373\n",
      "Epoch 132/800\n",
      "24/24 [==============================] - 0s 696us/sample - loss: 416.4893 - val_loss: 402.8964\n",
      "Epoch 133/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 416.1369 - val_loss: 402.5428\n",
      "Epoch 134/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 415.7818 - val_loss: 402.2180\n",
      "Epoch 135/800\n",
      "24/24 [==============================] - 0s 693us/sample - loss: 415.4240 - val_loss: 401.9140\n",
      "Epoch 136/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 415.0634 - val_loss: 401.5331\n",
      "Epoch 137/800\n",
      "24/24 [==============================] - 0s 680us/sample - loss: 414.7001 - val_loss: 401.1637\n",
      "Epoch 138/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 414.3341 - val_loss: 400.8108\n",
      "Epoch 139/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 413.9654 - val_loss: 400.4542\n",
      "Epoch 140/800\n",
      "24/24 [==============================] - 0s 669us/sample - loss: 413.5939 - val_loss: 400.0735\n",
      "Epoch 141/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 413.2197 - val_loss: 399.6861\n",
      "Epoch 142/800\n",
      "24/24 [==============================] - 0s 655us/sample - loss: 412.8428 - val_loss: 399.2870\n",
      "Epoch 143/800\n",
      "24/24 [==============================] - 0s 36us/sample - loss: 412.4633 - val_loss: 398.9306\n",
      "Epoch 144/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 412.0809 - val_loss: 398.5576\n",
      "Epoch 145/800\n",
      "24/24 [==============================] - 0s 695us/sample - loss: 411.6959 - val_loss: 398.1689\n",
      "Epoch 146/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 411.3081 - val_loss: 397.7452\n",
      "Epoch 147/800\n",
      "24/24 [==============================] - 0s 620us/sample - loss: 410.9177 - val_loss: 397.3343\n",
      "Epoch 148/800\n",
      "24/24 [==============================] - 0s 71us/sample - loss: 410.5245 - val_loss: 396.8978\n",
      "Epoch 149/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 410.1286 - val_loss: 396.4616\n",
      "Epoch 150/800\n",
      "24/24 [==============================] - 0s 698us/sample - loss: 409.7300 - val_loss: 396.0256\n",
      "Epoch 151/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 409.3288 - val_loss: 395.5941\n",
      "Epoch 152/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 408.9248 - val_loss: 395.1713\n",
      "Epoch 153/800\n",
      "24/24 [==============================] - 0s 724us/sample - loss: 408.5181 - val_loss: 394.7379\n",
      "Epoch 154/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 408.1087 - val_loss: 394.3282\n",
      "Epoch 155/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 407.6966 - val_loss: 393.9393\n",
      "Epoch 156/800\n",
      "24/24 [==============================] - 0s 69us/sample - loss: 407.2818 - val_loss: 393.4930\n",
      "Epoch 157/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 406.8643 - val_loss: 393.0293\n",
      "Epoch 158/800\n",
      "24/24 [==============================] - 0s 692us/sample - loss: 406.4442 - val_loss: 392.6086\n",
      "Epoch 159/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 406.0213 - val_loss: 392.1644\n",
      "Epoch 160/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 405.5958 - val_loss: 391.7589\n",
      "Epoch 161/800\n",
      "24/24 [==============================] - 0s 716us/sample - loss: 405.1675 - val_loss: 391.3221\n",
      "Epoch 162/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 404.7366 - val_loss: 390.8322\n",
      "Epoch 163/800\n",
      "24/24 [==============================] - 0s 606us/sample - loss: 404.3030 - val_loss: 390.4047\n",
      "Epoch 164/800\n",
      "24/24 [==============================] - 0s 34us/sample - loss: 403.8667 - val_loss: 389.9500\n",
      "Epoch 165/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 403.4277 - val_loss: 389.4894\n",
      "Epoch 166/800\n",
      "24/24 [==============================] - 0s 695us/sample - loss: 402.9860 - val_loss: 389.0403\n",
      "Epoch 167/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 402.5417 - val_loss: 388.6128\n",
      "Epoch 168/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 402.0947 - val_loss: 388.1743\n",
      "Epoch 169/800\n",
      "24/24 [==============================] - 0s 745us/sample - loss: 401.6450 - val_loss: 387.7466\n",
      "Epoch 170/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 401.1926 - val_loss: 387.2966\n",
      "Epoch 171/800\n",
      "24/24 [==============================] - 0s 578us/sample - loss: 400.7376 - val_loss: 386.8291\n",
      "Epoch 172/800\n",
      "24/24 [==============================] - 0s 32us/sample - loss: 400.2799 - val_loss: 386.3845\n",
      "Epoch 173/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 399.8195 - val_loss: 385.9035\n",
      "Epoch 174/800\n",
      "24/24 [==============================] - 0s 702us/sample - loss: 399.3565 - val_loss: 385.5037\n",
      "Epoch 175/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 398.8908 - val_loss: 385.0106\n",
      "Epoch 176/800\n",
      "24/24 [==============================] - 0s 653us/sample - loss: 398.4225 - val_loss: 384.5868\n",
      "Epoch 177/800\n",
      "24/24 [==============================] - 0s 39us/sample - loss: 397.9514 - val_loss: 384.1371\n",
      "Epoch 178/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 397.4777 - val_loss: 383.6964\n",
      "Epoch 179/800\n",
      "24/24 [==============================] - 0s 723us/sample - loss: 397.0014 - val_loss: 383.2111\n",
      "Epoch 180/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 396.5224 - val_loss: 382.7405\n",
      "Epoch 181/800\n",
      "24/24 [==============================] - 0s 589us/sample - loss: 396.0407 - val_loss: 382.1721\n",
      "Epoch 182/800\n",
      "24/24 [==============================] - 0s 42us/sample - loss: 395.5565 - val_loss: 381.6669\n",
      "Epoch 183/800\n",
      "24/24 [==============================] - 0s 618us/sample - loss: 395.0695 - val_loss: 381.1718\n",
      "Epoch 184/800\n",
      "24/24 [==============================] - 0s 85us/sample - loss: 394.5799 - val_loss: 380.6984\n",
      "Epoch 185/800\n",
      "24/24 [==============================] - 0s 610us/sample - loss: 394.0876 - val_loss: 380.2359\n",
      "Epoch 186/800\n",
      "24/24 [==============================] - 0s 60us/sample - loss: 393.5928 - val_loss: 379.7689\n",
      "Epoch 187/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 393.0952 - val_loss: 379.2085\n",
      "Epoch 188/800\n",
      "24/24 [==============================] - 0s 681us/sample - loss: 392.5950 - val_loss: 378.6987\n",
      "Epoch 189/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 392.0922 - val_loss: 378.1554\n",
      "Epoch 190/800\n",
      "24/24 [==============================] - 0s 560us/sample - loss: 391.5868 - val_loss: 377.6870\n",
      "Epoch 191/800\n",
      "24/24 [==============================] - 0s 36us/sample - loss: 391.0787 - val_loss: 377.2465\n",
      "Epoch 192/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 390.5680 - val_loss: 376.7071\n",
      "Epoch 193/800\n",
      "24/24 [==============================] - 0s 682us/sample - loss: 390.0546 - val_loss: 376.1604\n",
      "Epoch 194/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 389.5386 - val_loss: 375.6853\n",
      "Epoch 195/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 389.0200 - val_loss: 375.1079\n",
      "Epoch 196/800\n",
      "24/24 [==============================] - 0s 76us/sample - loss: 388.4988 - val_loss: 374.6034\n",
      "Epoch 197/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 387.9749 - val_loss: 374.0890\n",
      "Epoch 198/800\n",
      "24/24 [==============================] - 0s 731us/sample - loss: 387.4484 - val_loss: 373.5379\n",
      "Epoch 199/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 386.9193 - val_loss: 372.9423\n",
      "Epoch 200/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 386.3876 - val_loss: 372.3660\n",
      "Epoch 201/800\n",
      "24/24 [==============================] - 0s 658us/sample - loss: 385.8533 - val_loss: 371.8292\n",
      "Epoch 202/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 385.3163 - val_loss: 371.3176\n",
      "Epoch 203/800\n",
      "24/24 [==============================] - 0s 654us/sample - loss: 384.7768 - val_loss: 370.7458\n",
      "Epoch 204/800\n",
      "24/24 [==============================] - 0s 43us/sample - loss: 384.2346 - val_loss: 370.2293\n",
      "Epoch 205/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 383.6898 - val_loss: 369.7459\n",
      "Epoch 206/800\n",
      "24/24 [==============================] - 0s 689us/sample - loss: 383.1424 - val_loss: 369.1981\n",
      "Epoch 207/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 382.5924 - val_loss: 368.6878\n",
      "Epoch 208/800\n",
      "24/24 [==============================] - 0s 661us/sample - loss: 382.0398 - val_loss: 368.1742\n",
      "Epoch 209/800\n",
      "24/24 [==============================] - 0s 38us/sample - loss: 381.4846 - val_loss: 367.6111\n",
      "Epoch 210/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 380.9268 - val_loss: 367.1560\n",
      "Epoch 211/800\n",
      "24/24 [==============================] - 0s 704us/sample - loss: 380.3663 - val_loss: 366.6767\n",
      "Epoch 212/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 379.8034 - val_loss: 366.1249\n",
      "Epoch 213/800\n",
      "24/24 [==============================] - 0s 607us/sample - loss: 379.2377 - val_loss: 365.6028\n",
      "Epoch 214/800\n",
      "24/24 [==============================] - 0s 72us/sample - loss: 378.6696 - val_loss: 365.0329\n",
      "Epoch 215/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 378.0988 - val_loss: 364.5641\n",
      "Epoch 216/800\n",
      "24/24 [==============================] - 0s 693us/sample - loss: 377.5254 - val_loss: 364.0221\n",
      "Epoch 217/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 376.9494 - val_loss: 363.5624\n",
      "Epoch 218/800\n",
      "24/24 [==============================] - 0s 586us/sample - loss: 376.3709 - val_loss: 362.9919\n",
      "Epoch 219/800\n",
      "24/24 [==============================] - 0s 36us/sample - loss: 375.7897 - val_loss: 362.4259\n",
      "Epoch 220/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 375.2061 - val_loss: 361.9128\n",
      "Epoch 221/800\n",
      "24/24 [==============================] - 0s 694us/sample - loss: 374.6198 - val_loss: 361.3664\n",
      "Epoch 222/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 374.0309 - val_loss: 360.8137\n",
      "Epoch 223/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 373.4394 - val_loss: 360.2780\n",
      "Epoch 224/800\n",
      "24/24 [==============================] - 0s 696us/sample - loss: 372.8454 - val_loss: 359.6851\n",
      "Epoch 225/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 372.2488 - val_loss: 359.0794\n",
      "Epoch 226/800\n",
      "24/24 [==============================] - 0s 712us/sample - loss: 371.6497 - val_loss: 358.5112\n",
      "Epoch 227/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 371.0480 - val_loss: 357.9571\n",
      "Epoch 228/800\n",
      "24/24 [==============================] - 0s 743us/sample - loss: 370.4436 - val_loss: 357.4623\n",
      "Epoch 229/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 369.8368 - val_loss: 356.8893\n",
      "Epoch 230/800\n",
      "24/24 [==============================] - 0s 552us/sample - loss: 369.2274 - val_loss: 356.2427\n",
      "Epoch 231/800\n",
      "24/24 [==============================] - 0s 91us/sample - loss: 368.6154 - val_loss: 355.6602\n",
      "Epoch 232/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 368.0008 - val_loss: 355.1258\n",
      "Epoch 233/800\n",
      "24/24 [==============================] - 0s 640us/sample - loss: 367.3837 - val_loss: 354.5880\n",
      "Epoch 234/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 366.7641 - val_loss: 354.0541\n",
      "Epoch 235/800\n",
      "24/24 [==============================] - 0s 608us/sample - loss: 366.1418 - val_loss: 353.4929\n",
      "Epoch 236/800\n",
      "24/24 [==============================] - 0s 37us/sample - loss: 365.5171 - val_loss: 352.8759\n",
      "Epoch 237/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 364.8898 - val_loss: 352.2383\n",
      "Epoch 238/800\n",
      "24/24 [==============================] - 0s 695us/sample - loss: 364.2599 - val_loss: 351.5397\n",
      "Epoch 239/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 363.6275 - val_loss: 350.9358\n",
      "Epoch 240/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 362.9926 - val_loss: 350.3241\n",
      "Epoch 241/800\n",
      "24/24 [==============================] - 0s 700us/sample - loss: 362.3551 - val_loss: 349.6981\n",
      "Epoch 242/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 361.7150 - val_loss: 349.0703\n",
      "Epoch 243/800\n",
      "24/24 [==============================] - 0s 685us/sample - loss: 361.0725 - val_loss: 348.4807\n",
      "Epoch 244/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 360.4274 - val_loss: 347.8295\n",
      "Epoch 245/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 359.7798 - val_loss: 347.2261\n",
      "Epoch 246/800\n",
      "24/24 [==============================] - 0s 725us/sample - loss: 359.1296 - val_loss: 346.5663\n",
      "Epoch 247/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 358.4769 - val_loss: 345.9207\n",
      "Epoch 248/800\n",
      "24/24 [==============================] - 0s 633us/sample - loss: 357.8217 - val_loss: 345.2536\n",
      "Epoch 249/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 357.1639 - val_loss: 344.6898\n",
      "Epoch 250/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 356.5036 - val_loss: 344.1456\n",
      "Epoch 251/800\n",
      "24/24 [==============================] - 0s 698us/sample - loss: 355.8408 - val_loss: 343.7293\n",
      "Epoch 252/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 355.1754 - val_loss: 343.1807\n",
      "Epoch 253/800\n",
      "24/24 [==============================] - 0s 617us/sample - loss: 354.5076 - val_loss: 342.6424\n",
      "Epoch 254/800\n",
      "24/24 [==============================] - 0s 35us/sample - loss: 353.8372 - val_loss: 342.1542\n",
      "Epoch 255/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 353.1644 - val_loss: 341.6808\n",
      "Epoch 256/800\n",
      "24/24 [==============================] - 0s 691us/sample - loss: 352.4889 - val_loss: 341.1184\n",
      "Epoch 257/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 351.8110 - val_loss: 340.6079\n",
      "Epoch 258/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 351.1306 - val_loss: 340.0304\n",
      "Epoch 259/800\n",
      "24/24 [==============================] - 0s 705us/sample - loss: 350.4477 - val_loss: 339.3404\n",
      "Epoch 260/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 349.7622 - val_loss: 338.6207\n",
      "Epoch 261/800\n",
      "24/24 [==============================] - 0s 888us/sample - loss: 349.0743 - val_loss: 337.9061\n",
      "Epoch 262/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 348.3839 - val_loss: 337.1826\n",
      "Epoch 263/800\n",
      "24/24 [==============================] - 0s 514us/sample - loss: 347.6909 - val_loss: 336.5126\n",
      "Epoch 264/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 346.9955 - val_loss: 335.8314\n",
      "Epoch 265/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 346.2975 - val_loss: 335.1869\n",
      "Epoch 266/800\n",
      "24/24 [==============================] - 0s 123us/sample - loss: 345.5971 - val_loss: 334.4571\n",
      "Epoch 267/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 344.8942 - val_loss: 333.7647\n",
      "Epoch 268/800\n",
      "24/24 [==============================] - 0s 632us/sample - loss: 344.1888 - val_loss: 333.1058\n",
      "Epoch 269/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 343.4808 - val_loss: 332.4604\n",
      "Epoch 270/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 342.7704 - val_loss: 331.7778\n",
      "Epoch 271/800\n",
      "24/24 [==============================] - 0s 680us/sample - loss: 342.0575 - val_loss: 331.1845\n",
      "Epoch 272/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 341.3422 - val_loss: 330.6009\n",
      "Epoch 273/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 340.6243 - val_loss: 329.9253\n",
      "Epoch 274/800\n",
      "24/24 [==============================] - 0s 761us/sample - loss: 339.9040 - val_loss: 329.1190\n",
      "Epoch 275/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 339.1812 - val_loss: 328.4405\n",
      "Epoch 276/800\n",
      "24/24 [==============================] - 0s 625us/sample - loss: 338.4559 - val_loss: 327.6334\n",
      "Epoch 277/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 337.7281 - val_loss: 326.9133\n",
      "Epoch 278/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 336.9979 - val_loss: 326.1474\n",
      "Epoch 279/800\n",
      "24/24 [==============================] - 0s 713us/sample - loss: 336.2652 - val_loss: 325.4473\n",
      "Epoch 280/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 335.5300 - val_loss: 324.7144\n",
      "Epoch 281/800\n",
      "24/24 [==============================] - 0s 613us/sample - loss: 334.7923 - val_loss: 323.8253\n",
      "Epoch 282/800\n",
      "24/24 [==============================] - 0s 27us/sample - loss: 334.0522 - val_loss: 322.9751\n",
      "Epoch 283/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 333.3096 - val_loss: 322.1053\n",
      "Epoch 284/800\n",
      "24/24 [==============================] - 0s 748us/sample - loss: 332.5645 - val_loss: 321.2124\n",
      "Epoch 285/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 331.8171 - val_loss: 320.3981\n",
      "Epoch 286/800\n",
      "24/24 [==============================] - 0s 676us/sample - loss: 331.0671 - val_loss: 319.5887\n",
      "Epoch 287/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 330.3147 - val_loss: 318.6783\n",
      "Epoch 288/800\n",
      "24/24 [==============================] - 0s 615us/sample - loss: 329.5598 - val_loss: 317.9579\n",
      "Epoch 289/800\n",
      "24/24 [==============================] - 0s 63us/sample - loss: 328.8025 - val_loss: 317.2798\n",
      "Epoch 290/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 328.0427 - val_loss: 316.6303\n",
      "Epoch 291/800\n",
      "24/24 [==============================] - 0s 665us/sample - loss: 327.2805 - val_loss: 316.0175\n",
      "Epoch 292/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 326.5158 - val_loss: 315.4507\n",
      "Epoch 293/800\n",
      "24/24 [==============================] - 0s 627us/sample - loss: 325.7487 - val_loss: 314.7549\n",
      "Epoch 294/800\n",
      "24/24 [==============================] - 0s 36us/sample - loss: 324.9791 - val_loss: 313.9901\n",
      "Epoch 295/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 324.2071 - val_loss: 313.2189\n",
      "Epoch 296/800\n",
      "24/24 [==============================] - 0s 695us/sample - loss: 323.4326 - val_loss: 312.5367\n",
      "Epoch 297/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 322.6557 - val_loss: 311.7563\n",
      "Epoch 298/800\n",
      "24/24 [==============================] - 0s 687us/sample - loss: 321.8764 - val_loss: 310.8661\n",
      "Epoch 299/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 321.0946 - val_loss: 310.0372\n",
      "Epoch 300/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 320.3104 - val_loss: 309.2834\n",
      "Epoch 301/800\n",
      "24/24 [==============================] - 0s 700us/sample - loss: 319.5238 - val_loss: 308.6159\n",
      "Epoch 302/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 318.7348 - val_loss: 307.8900\n",
      "Epoch 303/800\n",
      "24/24 [==============================] - 0s 655us/sample - loss: 317.9433 - val_loss: 307.2148\n",
      "Epoch 304/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 317.1494 - val_loss: 306.5294\n",
      "Epoch 305/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 316.3530 - val_loss: 305.8225\n",
      "Epoch 306/800\n",
      "24/24 [==============================] - 0s 741us/sample - loss: 315.5542 - val_loss: 305.0710\n",
      "Epoch 307/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 314.7531 - val_loss: 304.4201\n",
      "Epoch 308/800\n",
      "24/24 [==============================] - 0s 566us/sample - loss: 313.9495 - val_loss: 303.6832\n",
      "Epoch 309/800\n",
      "24/24 [==============================] - 0s 160us/sample - loss: 313.1435 - val_loss: 302.7476\n",
      "Epoch 310/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 312.3350 - val_loss: 301.8984\n",
      "Epoch 311/800\n",
      "24/24 [==============================] - 0s 621us/sample - loss: 311.5242 - val_loss: 301.1733\n",
      "Epoch 312/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 310.7109 - val_loss: 300.4169\n",
      "Epoch 313/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 309.8952 - val_loss: 299.5899\n",
      "Epoch 314/800\n",
      "24/24 [==============================] - 0s 703us/sample - loss: 309.0772 - val_loss: 298.7572\n",
      "Epoch 315/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 308.2567 - val_loss: 297.9832\n",
      "Epoch 316/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 307.4338 - val_loss: 297.1091\n",
      "Epoch 317/800\n",
      "24/24 [==============================] - 0s 70us/sample - loss: 306.6085 - val_loss: 296.3570\n",
      "Epoch 318/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 305.7808 - val_loss: 295.5345\n",
      "Epoch 319/800\n",
      "24/24 [==============================] - 0s 694us/sample - loss: 304.9507 - val_loss: 294.6677\n",
      "Epoch 320/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 304.1182 - val_loss: 293.8753\n",
      "Epoch 321/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 303.2833 - val_loss: 293.1444\n",
      "Epoch 322/800\n",
      "24/24 [==============================] - 0s 801us/sample - loss: 302.4460 - val_loss: 292.3384\n",
      "Epoch 323/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 301.6063 - val_loss: 291.6337\n",
      "Epoch 324/800\n",
      "24/24 [==============================] - 0s 142us/sample - loss: 300.7643 - val_loss: 290.8181\n",
      "Epoch 325/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 299.9198 - val_loss: 289.9798\n",
      "Epoch 326/800\n",
      "24/24 [==============================] - 0s 638us/sample - loss: 299.0730 - val_loss: 289.3243\n",
      "Epoch 327/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 298.2237 - val_loss: 288.5137\n",
      "Epoch 328/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 297.3721 - val_loss: 287.6921\n",
      "Epoch 329/800\n",
      "24/24 [==============================] - 0s 147us/sample - loss: 296.5181 - val_loss: 286.9396\n",
      "Epoch 330/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 295.6617 - val_loss: 286.0478\n",
      "Epoch 331/800\n",
      "24/24 [==============================] - 0s 633us/sample - loss: 294.8030 - val_loss: 285.2585\n",
      "Epoch 332/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 293.9418 - val_loss: 284.4648\n",
      "Epoch 333/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 293.0783 - val_loss: 283.6431\n",
      "Epoch 334/800\n",
      "24/24 [==============================] - 0s 702us/sample - loss: 292.2124 - val_loss: 282.8467\n",
      "Epoch 335/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 291.3442 - val_loss: 281.9672\n",
      "Epoch 336/800\n",
      "24/24 [==============================] - 0s 601us/sample - loss: 290.4736 - val_loss: 281.0734\n",
      "Epoch 337/800\n",
      "24/24 [==============================] - 0s 74us/sample - loss: 289.6006 - val_loss: 280.2885\n",
      "Epoch 338/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 288.7252 - val_loss: 279.4148\n",
      "Epoch 339/800\n",
      "24/24 [==============================] - 0s 683us/sample - loss: 287.8475 - val_loss: 278.5977\n",
      "Epoch 340/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 286.9674 - val_loss: 277.8248\n",
      "Epoch 341/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 286.0849 - val_loss: 277.1019\n",
      "Epoch 342/800\n",
      "24/24 [==============================] - 0s 687us/sample - loss: 285.2001 - val_loss: 276.2832\n",
      "Epoch 343/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 284.3129 - val_loss: 275.3293\n",
      "Epoch 344/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 283.4234 - val_loss: 274.0894\n",
      "Epoch 345/800\n",
      "24/24 [==============================] - 0s 73us/sample - loss: 282.5315 - val_loss: 273.1970\n",
      "Epoch 346/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 281.6373 - val_loss: 272.1688\n",
      "Epoch 347/800\n",
      "24/24 [==============================] - 0s 692us/sample - loss: 280.7407 - val_loss: 271.1880\n",
      "Epoch 348/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 279.8418 - val_loss: 270.2358\n",
      "Epoch 349/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 278.9405 - val_loss: 269.3819\n",
      "Epoch 350/800\n",
      "24/24 [==============================] - 0s 710us/sample - loss: 278.0369 - val_loss: 268.4440\n",
      "Epoch 351/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 277.1309 - val_loss: 267.5983\n",
      "Epoch 352/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 276.2226 - val_loss: 266.5607\n",
      "Epoch 353/800\n",
      "24/24 [==============================] - 0s 72us/sample - loss: 275.3119 - val_loss: 265.6210\n",
      "Epoch 354/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 274.3989 - val_loss: 264.6963\n",
      "Epoch 355/800\n",
      "24/24 [==============================] - 0s 679us/sample - loss: 273.4836 - val_loss: 263.9166\n",
      "Epoch 356/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 272.5659 - val_loss: 263.0766\n",
      "Epoch 357/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 271.6459 - val_loss: 262.2634\n",
      "Epoch 358/800\n",
      "24/24 [==============================] - 0s 694us/sample - loss: 270.7236 - val_loss: 261.3651\n",
      "Epoch 359/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 269.7989 - val_loss: 260.4215\n",
      "Epoch 360/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 268.8719 - val_loss: 259.4862\n",
      "Epoch 361/800\n",
      "24/24 [==============================] - 0s 120us/sample - loss: 267.9425 - val_loss: 258.6528\n",
      "Epoch 362/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 267.0109 - val_loss: 257.6986\n",
      "Epoch 363/800\n",
      "24/24 [==============================] - 0s 664us/sample - loss: 266.0769 - val_loss: 256.6453\n",
      "Epoch 364/800\n",
      "24/24 [==============================] - 0s 8us/sample - loss: 265.1406 - val_loss: 255.6295\n",
      "Epoch 365/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 264.2020 - val_loss: 254.4242\n",
      "Epoch 366/800\n",
      "24/24 [==============================] - 0s 690us/sample - loss: 263.2610 - val_loss: 253.1354\n",
      "Epoch 367/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 262.3178 - val_loss: 252.0530\n",
      "Epoch 368/800\n",
      "24/24 [==============================] - 0s 691us/sample - loss: 261.3722 - val_loss: 251.0744\n",
      "Epoch 369/800\n",
      "24/24 [==============================] - 0s 58us/sample - loss: 260.4243 - val_loss: 250.0504\n",
      "Epoch 370/800\n",
      "24/24 [==============================] - 0s 652us/sample - loss: 259.4741 - val_loss: 249.1102\n",
      "Epoch 371/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 258.5216 - val_loss: 247.9971\n",
      "Epoch 372/800\n",
      "24/24 [==============================] - 0s 530us/sample - loss: 257.5668 - val_loss: 246.9505\n",
      "Epoch 373/800\n",
      "24/24 [==============================] - 0s 37us/sample - loss: 256.6097 - val_loss: 245.8285\n",
      "Epoch 374/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 255.6502 - val_loss: 244.7476\n",
      "Epoch 375/800\n",
      "24/24 [==============================] - 0s 729us/sample - loss: 254.6885 - val_loss: 243.6496\n",
      "Epoch 376/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 253.7244 - val_loss: 242.4693\n",
      "Epoch 377/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 252.7581 - val_loss: 241.3634\n",
      "Epoch 378/800\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 251.7895 - val_loss: 240.2609\n",
      "Epoch 379/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 250.8185 - val_loss: 239.1724\n",
      "Epoch 380/800\n",
      "24/24 [==============================] - 0s 632us/sample - loss: 249.8453 - val_loss: 238.1748\n",
      "Epoch 381/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 248.8698 - val_loss: 237.2612\n",
      "Epoch 382/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 247.8919 - val_loss: 236.2688\n",
      "Epoch 383/800\n",
      "24/24 [==============================] - 0s 744us/sample - loss: 246.9118 - val_loss: 235.2345\n",
      "Epoch 384/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 245.9294 - val_loss: 234.3397\n",
      "Epoch 385/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 244.9447 - val_loss: 233.5227\n",
      "Epoch 386/800\n",
      "24/24 [==============================] - 0s 713us/sample - loss: 243.9577 - val_loss: 232.6577\n",
      "Epoch 387/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 242.9684 - val_loss: 231.9973\n",
      "Epoch 388/800\n",
      "24/24 [==============================] - 0s 603us/sample - loss: 241.9769 - val_loss: 231.0144\n",
      "Epoch 389/800\n",
      "24/24 [==============================] - 0s 26us/sample - loss: 240.9830 - val_loss: 230.2619\n",
      "Epoch 390/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 239.9869 - val_loss: 229.6833\n",
      "Epoch 391/800\n",
      "24/24 [==============================] - 0s 698us/sample - loss: 238.9885 - val_loss: 229.0170\n",
      "Epoch 392/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 237.9879 - val_loss: 228.2417\n",
      "Epoch 393/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 236.9849 - val_loss: 227.5191\n",
      "Epoch 394/800\n",
      "24/24 [==============================] - 0s 74us/sample - loss: 235.9797 - val_loss: 226.7593\n",
      "Epoch 395/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 234.9722 - val_loss: 225.7987\n",
      "Epoch 396/800\n",
      "24/24 [==============================] - 0s 691us/sample - loss: 233.9625 - val_loss: 224.8017\n",
      "Epoch 397/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 232.9504 - val_loss: 223.7151\n",
      "Epoch 398/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 231.9361 - val_loss: 222.5788\n",
      "Epoch 399/800\n",
      "24/24 [==============================] - 0s 712us/sample - loss: 230.9196 - val_loss: 221.3201\n",
      "Epoch 400/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 229.9007 - val_loss: 219.8806\n",
      "Epoch 401/800\n",
      "24/24 [==============================] - 0s 668us/sample - loss: 228.8797 - val_loss: 218.4126\n",
      "Epoch 402/800\n",
      "24/24 [==============================] - 0s 5us/sample - loss: 227.8563 - val_loss: 216.9908\n",
      "Epoch 403/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 226.8307 - val_loss: 215.6602\n",
      "Epoch 404/800\n",
      "24/24 [==============================] - 0s 685us/sample - loss: 225.8028 - val_loss: 214.4644\n",
      "Epoch 405/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 224.7727 - val_loss: 213.4123\n",
      "Epoch 406/800\n",
      "24/24 [==============================] - 0s 603us/sample - loss: 223.7403 - val_loss: 212.1867\n",
      "Epoch 407/800\n",
      "24/24 [==============================] - 0s 134us/sample - loss: 222.7057 - val_loss: 211.0176\n",
      "Epoch 408/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 221.6688 - val_loss: 210.0190\n",
      "Epoch 409/800\n",
      "24/24 [==============================] - 0s 630us/sample - loss: 220.6297 - val_loss: 209.1021\n",
      "Epoch 410/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 219.5883 - val_loss: 208.1696\n",
      "Epoch 411/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 218.5447 - val_loss: 207.1955\n",
      "Epoch 412/800\n",
      "24/24 [==============================] - 0s 716us/sample - loss: 217.4988 - val_loss: 206.2590\n",
      "Epoch 413/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 216.4507 - val_loss: 205.2335\n",
      "Epoch 414/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 215.4004 - val_loss: 204.2313\n",
      "Epoch 415/800\n",
      "24/24 [==============================] - 0s 70us/sample - loss: 214.3478 - val_loss: 203.0565\n",
      "Epoch 416/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 213.2929 - val_loss: 202.0715\n",
      "Epoch 417/800\n",
      "24/24 [==============================] - 0s 759us/sample - loss: 212.2358 - val_loss: 201.2684\n",
      "Epoch 418/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 211.1765 - val_loss: 200.2663\n",
      "Epoch 419/800\n",
      "24/24 [==============================] - 0s 766us/sample - loss: 210.1150 - val_loss: 199.3020\n",
      "Epoch 420/800\n",
      "24/24 [==============================] - 0s 45us/sample - loss: 209.0512 - val_loss: 198.2773\n",
      "Epoch 421/800\n",
      "24/24 [==============================] - 0s 467us/sample - loss: 207.9852 - val_loss: 197.1151\n",
      "Epoch 422/800\n",
      "24/24 [==============================] - 0s 26us/sample - loss: 206.9170 - val_loss: 195.9053\n",
      "Epoch 423/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 205.8465 - val_loss: 194.8669\n",
      "Epoch 424/800\n",
      "24/24 [==============================] - 0s 732us/sample - loss: 204.7738 - val_loss: 193.5000\n",
      "Epoch 425/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 203.6989 - val_loss: 192.1507\n",
      "Epoch 426/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 202.6218 - val_loss: 190.9126\n",
      "Epoch 427/800\n",
      "24/24 [==============================] - 0s 691us/sample - loss: 201.5424 - val_loss: 189.7780\n",
      "Epoch 428/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 200.4608 - val_loss: 188.6712\n",
      "Epoch 429/800\n",
      "24/24 [==============================] - 0s 618us/sample - loss: 199.3770 - val_loss: 187.4292\n",
      "Epoch 430/800\n",
      "24/24 [==============================] - 0s 55us/sample - loss: 198.2910 - val_loss: 186.3046\n",
      "Epoch 431/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 197.2028 - val_loss: 185.0708\n",
      "Epoch 432/800\n",
      "24/24 [==============================] - 0s 693us/sample - loss: 196.1123 - val_loss: 183.7347\n",
      "Epoch 433/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 195.0197 - val_loss: 182.7655\n",
      "Epoch 434/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 193.9248 - val_loss: 181.8735\n",
      "Epoch 435/800\n",
      "24/24 [==============================] - 0s 704us/sample - loss: 192.8277 - val_loss: 180.7062\n",
      "Epoch 436/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 191.7284 - val_loss: 179.4714\n",
      "Epoch 437/800\n",
      "24/24 [==============================] - 0s 618us/sample - loss: 190.6269 - val_loss: 178.4424\n",
      "Epoch 438/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 189.5232 - val_loss: 177.1920\n",
      "Epoch 439/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 188.4173 - val_loss: 175.8586\n",
      "Epoch 440/800\n",
      "24/24 [==============================] - 0s 695us/sample - loss: 187.3092 - val_loss: 174.6254\n",
      "Epoch 441/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 186.1989 - val_loss: 173.3568\n",
      "Epoch 442/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 185.0864 - val_loss: 172.0408\n",
      "Epoch 443/800\n",
      "24/24 [==============================] - 0s 71us/sample - loss: 183.9717 - val_loss: 170.8003\n",
      "Epoch 444/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 182.8548 - val_loss: 169.7979\n",
      "Epoch 445/800\n",
      "24/24 [==============================] - 0s 659us/sample - loss: 181.7357 - val_loss: 168.6576\n",
      "Epoch 446/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 180.6145 - val_loss: 167.6182\n",
      "Epoch 447/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 179.4910 - val_loss: 166.7250\n",
      "Epoch 448/800\n",
      "24/24 [==============================] - 0s 737us/sample - loss: 178.3653 - val_loss: 165.6812\n",
      "Epoch 449/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 177.2374 - val_loss: 164.5809\n",
      "Epoch 450/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 176.1074 - val_loss: 163.4593\n",
      "Epoch 451/800\n",
      "24/24 [==============================] - 0s 69us/sample - loss: 174.9752 - val_loss: 162.1573\n",
      "Epoch 452/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 173.8408 - val_loss: 161.0919\n",
      "Epoch 453/800\n",
      "24/24 [==============================] - 0s 696us/sample - loss: 172.7042 - val_loss: 159.9348\n",
      "Epoch 454/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 171.5654 - val_loss: 158.8838\n",
      "Epoch 455/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 170.4244 - val_loss: 157.7361\n",
      "Epoch 456/800\n",
      "24/24 [==============================] - 0s 739us/sample - loss: 169.2813 - val_loss: 156.6653\n",
      "Epoch 457/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 168.1360 - val_loss: 155.7141\n",
      "Epoch 458/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 166.9885 - val_loss: 154.5342\n",
      "Epoch 459/800\n",
      "24/24 [==============================] - 0s 775us/sample - loss: 165.8389 - val_loss: 153.1849\n",
      "Epoch 460/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 164.6870 - val_loss: 151.8787\n",
      "Epoch 461/800\n",
      "24/24 [==============================] - 0s 794us/sample - loss: 163.5330 - val_loss: 150.3634\n",
      "Epoch 462/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 162.3768 - val_loss: 148.9564\n",
      "Epoch 463/800\n",
      "24/24 [==============================] - 0s 541us/sample - loss: 161.2185 - val_loss: 147.9556\n",
      "Epoch 464/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 160.0580 - val_loss: 146.8357\n",
      "Epoch 465/800\n",
      "24/24 [==============================] - 0s 553us/sample - loss: 158.8953 - val_loss: 145.4853\n",
      "Epoch 466/800\n",
      "24/24 [==============================] - 0s 80us/sample - loss: 157.7305 - val_loss: 144.3591\n",
      "Epoch 467/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 156.5635 - val_loss: 143.5578\n",
      "Epoch 468/800\n",
      "24/24 [==============================] - 0s 691us/sample - loss: 155.3943 - val_loss: 142.5885\n",
      "Epoch 469/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 154.2230 - val_loss: 141.3203\n",
      "Epoch 470/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 153.0496 - val_loss: 139.9226\n",
      "Epoch 471/800\n",
      "24/24 [==============================] - 0s 696us/sample - loss: 151.8739 - val_loss: 138.6359\n",
      "Epoch 472/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 150.6962 - val_loss: 137.3490\n",
      "Epoch 473/800\n",
      "24/24 [==============================] - 0s 567us/sample - loss: 149.5162 - val_loss: 136.2152\n",
      "Epoch 474/800\n",
      "24/24 [==============================] - 0s 92us/sample - loss: 148.3341 - val_loss: 134.9279\n",
      "Epoch 475/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 147.1499 - val_loss: 133.6263\n",
      "Epoch 476/800\n",
      "24/24 [==============================] - 0s 692us/sample - loss: 145.9635 - val_loss: 132.4995\n",
      "Epoch 477/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 144.7750 - val_loss: 131.3403\n",
      "Epoch 478/800\n",
      "24/24 [==============================] - 0s 564us/sample - loss: 143.5843 - val_loss: 130.2763\n",
      "Epoch 479/800\n",
      "24/24 [==============================] - 0s 113us/sample - loss: 142.3914 - val_loss: 129.3563\n",
      "Epoch 480/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 141.1965 - val_loss: 128.3862\n",
      "Epoch 481/800\n",
      "24/24 [==============================] - 0s 666us/sample - loss: 139.9994 - val_loss: 127.4971\n",
      "Epoch 482/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 138.8001 - val_loss: 126.4189\n",
      "Epoch 483/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 137.5987 - val_loss: 125.2491\n",
      "Epoch 484/800\n",
      "24/24 [==============================] - 0s 741us/sample - loss: 136.3952 - val_loss: 123.9933\n",
      "Epoch 485/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 135.1895 - val_loss: 122.5570\n",
      "Epoch 486/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 133.9817 - val_loss: 121.2012\n",
      "Epoch 487/800\n",
      "24/24 [==============================] - 0s 90us/sample - loss: 132.7718 - val_loss: 120.0128\n",
      "Epoch 488/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 131.5597 - val_loss: 118.8873\n",
      "Epoch 489/800\n",
      "24/24 [==============================] - 0s 669us/sample - loss: 130.3456 - val_loss: 117.8350\n",
      "Epoch 490/800\n",
      "24/24 [==============================] - 0s 40us/sample - loss: 129.1292 - val_loss: 116.9868\n",
      "Epoch 491/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 127.9108 - val_loss: 116.2326\n",
      "Epoch 492/800\n",
      "24/24 [==============================] - 0s 663us/sample - loss: 126.6902 - val_loss: 115.2635\n",
      "Epoch 493/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 125.4675 - val_loss: 114.2191\n",
      "Epoch 494/800\n",
      "24/24 [==============================] - 0s 732us/sample - loss: 124.2427 - val_loss: 113.3942\n",
      "Epoch 495/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 123.0157 - val_loss: 112.3608\n",
      "Epoch 496/800\n",
      "24/24 [==============================] - 0s 703us/sample - loss: 121.7866 - val_loss: 111.3371\n",
      "Epoch 497/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 120.5555 - val_loss: 110.3082\n",
      "Epoch 498/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 119.3222 - val_loss: 109.0783\n",
      "Epoch 499/800\n",
      "24/24 [==============================] - 0s 673us/sample - loss: 118.0867 - val_loss: 107.8653\n",
      "Epoch 500/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 116.8492 - val_loss: 106.9045\n",
      "Epoch 501/800\n",
      "24/24 [==============================] - 0s 622us/sample - loss: 115.6096 - val_loss: 105.8689\n",
      "Epoch 502/800\n",
      "24/24 [==============================] - 0s 42us/sample - loss: 114.3678 - val_loss: 104.7422\n",
      "Epoch 503/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 113.1239 - val_loss: 103.4915\n",
      "Epoch 504/800\n",
      "24/24 [==============================] - 0s 691us/sample - loss: 111.8780 - val_loss: 102.0757\n",
      "Epoch 505/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 110.6298 - val_loss: 100.5432\n",
      "Epoch 506/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 109.3797 - val_loss: 98.9790\n",
      "Epoch 507/800\n",
      "24/24 [==============================] - 0s 701us/sample - loss: 108.1274 - val_loss: 97.4150\n",
      "Epoch 508/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 106.8730 - val_loss: 95.9218\n",
      "Epoch 509/800\n",
      "24/24 [==============================] - 0s 628us/sample - loss: 105.6165 - val_loss: 94.4180\n",
      "Epoch 510/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 104.3578 - val_loss: 93.0623\n",
      "Epoch 511/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 103.0971 - val_loss: 91.8777\n",
      "Epoch 512/800\n",
      "24/24 [==============================] - 0s 717us/sample - loss: 101.8343 - val_loss: 90.7378\n",
      "Epoch 513/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 100.5694 - val_loss: 89.7645\n",
      "Epoch 514/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 99.3025 - val_loss: 88.3964\n",
      "Epoch 515/800\n",
      "24/24 [==============================] - 0s 125us/sample - loss: 98.0333 - val_loss: 87.0491\n",
      "Epoch 516/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 96.7621 - val_loss: 85.6163\n",
      "Epoch 517/800\n",
      "24/24 [==============================] - 0s 660us/sample - loss: 95.4889 - val_loss: 84.2361\n",
      "Epoch 518/800\n",
      "24/24 [==============================] - 0s 48us/sample - loss: 94.2135 - val_loss: 82.6154\n",
      "Epoch 519/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 92.9361 - val_loss: 81.2646\n",
      "Epoch 520/800\n",
      "24/24 [==============================] - 0s 647us/sample - loss: 91.6565 - val_loss: 80.1434\n",
      "Epoch 521/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 90.3749 - val_loss: 78.8705\n",
      "Epoch 522/800\n",
      "24/24 [==============================] - 0s 602us/sample - loss: 89.0912 - val_loss: 77.6505\n",
      "Epoch 523/800\n",
      "24/24 [==============================] - 0s 73us/sample - loss: 87.8053 - val_loss: 76.4473\n",
      "Epoch 524/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 86.5175 - val_loss: 75.0050\n",
      "Epoch 525/800\n",
      "24/24 [==============================] - 0s 692us/sample - loss: 85.2275 - val_loss: 73.5488\n",
      "Epoch 526/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 83.9355 - val_loss: 72.3281\n",
      "Epoch 527/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 82.6414 - val_loss: 71.2763\n",
      "Epoch 528/800\n",
      "24/24 [==============================] - 0s 814us/sample - loss: 81.6218 - val_loss: 68.7232\n",
      "Epoch 529/800\n",
      "24/24 [==============================] - 0s 508us/sample - loss: 80.2343 - val_loss: 66.0749\n",
      "Epoch 530/800\n",
      "24/24 [==============================] - 0s 118us/sample - loss: 78.7973 - val_loss: 62.4538\n",
      "Epoch 531/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 77.5277 - val_loss: 57.3893\n",
      "Epoch 532/800\n",
      "24/24 [==============================] - 0s 618us/sample - loss: 76.7261 - val_loss: 58.3667\n",
      "Epoch 533/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 81.2334 - val_loss: 61.8460\n",
      "Epoch 534/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 74.9709 - val_loss: 62.4096\n",
      "Epoch 535/800\n",
      "24/24 [==============================] - 0s 689us/sample - loss: 73.1696 - val_loss: 60.4525\n",
      "Epoch 536/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 71.8544 - val_loss: 60.4099\n",
      "Epoch 537/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 70.1522 - val_loss: 61.2849\n",
      "Epoch 538/800\n",
      "24/24 [==============================] - 0s 654us/sample - loss: 69.8741 - val_loss: 58.6365\n",
      "Epoch 539/800\n",
      "24/24 [==============================] - 0s 8us/sample - loss: 68.9469 - val_loss: 55.1327\n",
      "Epoch 540/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 66.9443 - val_loss: 47.8712\n",
      "Epoch 541/800\n",
      "24/24 [==============================] - 0s 703us/sample - loss: 66.1520 - val_loss: 42.0974\n",
      "Epoch 542/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 64.4118 - val_loss: 36.5112\n",
      "Epoch 543/800\n",
      "24/24 [==============================] - 0s 613us/sample - loss: 63.6277 - val_loss: 34.8769\n",
      "Epoch 544/800\n",
      "24/24 [==============================] - 0s 92us/sample - loss: 62.9662 - val_loss: 38.2861\n",
      "Epoch 545/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 60.9820 - val_loss: 42.5335\n",
      "Epoch 546/800\n",
      "24/24 [==============================] - 0s 590us/sample - loss: 60.9169 - val_loss: 43.5925\n",
      "Epoch 547/800\n",
      "24/24 [==============================] - 0s 27us/sample - loss: 58.2429 - val_loss: 44.3737\n",
      "Epoch 548/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 57.5850 - val_loss: 43.1624\n",
      "Epoch 549/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 61.5648 - val_loss: 43.6993\n",
      "Epoch 550/800\n",
      "24/24 [==============================] - 0s 132us/sample - loss: 59.1891 - val_loss: 44.2230\n",
      "Epoch 551/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 56.3942 - val_loss: 44.5773\n",
      "Epoch 552/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 60.4229 - val_loss: 43.9685\n",
      "Epoch 553/800\n",
      "24/24 [==============================] - 0s 653us/sample - loss: 55.3711 - val_loss: 40.7041\n",
      "Epoch 554/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 56.5258 - val_loss: 36.9167\n",
      "Epoch 555/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 50.8094 - val_loss: 34.4766\n",
      "Epoch 556/800\n",
      "24/24 [==============================] - 0s 731us/sample - loss: 53.2802 - val_loss: 33.4895\n",
      "Epoch 557/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 49.9866 - val_loss: 32.5583\n",
      "Epoch 558/800\n",
      "24/24 [==============================] - 0s 627us/sample - loss: 51.6890 - val_loss: 30.8993\n",
      "Epoch 559/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 53.4165 - val_loss: 27.8537\n",
      "Epoch 560/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 47.4435 - val_loss: 24.4092\n",
      "Epoch 561/800\n",
      "24/24 [==============================] - 0s 808us/sample - loss: 46.0306 - val_loss: 22.1096\n",
      "Epoch 562/800\n",
      "24/24 [==============================] - 0s 534us/sample - loss: 46.1974 - val_loss: 21.6644\n",
      "Epoch 563/800\n",
      "24/24 [==============================] - 0s 71us/sample - loss: 48.8252 - val_loss: 21.0582\n",
      "Epoch 564/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 48.8727 - val_loss: 17.7849\n",
      "Epoch 565/800\n",
      "24/24 [==============================] - 0s 713us/sample - loss: 47.5834 - val_loss: 15.1621\n",
      "Epoch 566/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 49.2225 - val_loss: 14.1024\n",
      "Epoch 567/800\n",
      "24/24 [==============================] - 0s 561us/sample - loss: 43.6480 - val_loss: 13.8744\n",
      "Epoch 568/800\n",
      "24/24 [==============================] - 0s 75us/sample - loss: 42.1663 - val_loss: 13.9417\n",
      "Epoch 569/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 47.5630 - val_loss: 12.6424\n",
      "Epoch 570/800\n",
      "24/24 [==============================] - 0s 653us/sample - loss: 42.2385 - val_loss: 11.5970\n",
      "Epoch 571/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 42.6326 - val_loss: 10.4877\n",
      "Epoch 572/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 44.6130 - val_loss: 10.5330\n",
      "Epoch 573/800\n",
      "24/24 [==============================] - 0s 697us/sample - loss: 44.0747 - val_loss: 10.5370\n",
      "Epoch 574/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 38.2611 - val_loss: 11.7509\n",
      "Epoch 575/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 37.0104 - val_loss: 12.6802\n",
      "Epoch 576/800\n",
      "24/24 [==============================] - 0s 611us/sample - loss: 40.7890 - val_loss: 12.7657\n",
      "Epoch 577/800\n",
      "24/24 [==============================] - 0s 38us/sample - loss: 42.6093 - val_loss: 12.6480\n",
      "Epoch 578/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 35.1536 - val_loss: 12.3391\n",
      "Epoch 579/800\n",
      "24/24 [==============================] - 0s 579us/sample - loss: 34.3279 - val_loss: 12.7963\n",
      "Epoch 580/800\n",
      "24/24 [==============================] - 0s 70us/sample - loss: 38.5443 - val_loss: 13.2863\n",
      "Epoch 581/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 34.8339 - val_loss: 13.3625\n",
      "Epoch 582/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 30.9422 - val_loss: 14.4379\n",
      "Epoch 583/800\n",
      "24/24 [==============================] - 0s 706us/sample - loss: 32.8299 - val_loss: 14.4942\n",
      "Epoch 584/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 32.3924 - val_loss: 16.2149\n",
      "Epoch 585/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 30.9980 - val_loss: 16.0506\n",
      "Epoch 586/800\n",
      "24/24 [==============================] - 0s 687us/sample - loss: 38.7444 - val_loss: 15.4390\n",
      "Epoch 587/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 35.9681 - val_loss: 14.2123\n",
      "Epoch 588/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 41.0443 - val_loss: 11.3491\n",
      "Epoch 589/800\n",
      "24/24 [==============================] - 0s 725us/sample - loss: 28.6400 - val_loss: 8.4831\n",
      "Epoch 590/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 27.3999 - val_loss: 8.3203\n",
      "Epoch 591/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 32.6854 - val_loss: 8.1671\n",
      "Epoch 592/800\n",
      "24/24 [==============================] - 0s 706us/sample - loss: 26.7375 - val_loss: 8.4415\n",
      "Epoch 593/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 35.4686 - val_loss: 8.5552\n",
      "Epoch 594/800\n",
      "24/24 [==============================] - 0s 768us/sample - loss: 34.1272 - val_loss: 8.3659\n",
      "Epoch 595/800\n",
      "24/24 [==============================] - 0s 50us/sample - loss: 27.0313 - val_loss: 8.7624\n",
      "Epoch 596/800\n",
      "24/24 [==============================] - 0s 457us/sample - loss: 30.3056 - val_loss: 9.6821\n",
      "Epoch 597/800\n",
      "24/24 [==============================] - 0s 26us/sample - loss: 29.6740 - val_loss: 9.1507\n",
      "Epoch 598/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 24.2599 - val_loss: 7.6580\n",
      "Epoch 599/800\n",
      "24/24 [==============================] - 0s 642us/sample - loss: 32.2695 - val_loss: 8.1897\n",
      "Epoch 600/800\n",
      "24/24 [==============================] - 0s 35us/sample - loss: 30.6108 - val_loss: 8.5125\n",
      "Epoch 601/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 41.7599 - val_loss: 8.5621\n",
      "Epoch 602/800\n",
      "24/24 [==============================] - 0s 628us/sample - loss: 29.8993 - val_loss: 7.1377\n",
      "Epoch 603/800\n",
      "24/24 [==============================] - 0s 82us/sample - loss: 33.9914 - val_loss: 6.0500\n",
      "Epoch 604/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 30.2130 - val_loss: 4.8342\n",
      "Epoch 605/800\n",
      "24/24 [==============================] - 0s 700us/sample - loss: 24.9604 - val_loss: 3.7653\n",
      "Epoch 606/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 21.7759 - val_loss: 3.2186\n",
      "Epoch 607/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 22.1410 - val_loss: 5.5057\n",
      "Epoch 608/800\n",
      "24/24 [==============================] - 0s 677us/sample - loss: 30.9302 - val_loss: 7.0648\n",
      "Epoch 609/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 25.7956 - val_loss: 7.7519\n",
      "Epoch 610/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 32.7882 - val_loss: 7.9826\n",
      "Epoch 611/800\n",
      "24/24 [==============================] - 0s 707us/sample - loss: 32.9820 - val_loss: 7.4080\n",
      "Epoch 612/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 37.4312 - val_loss: 7.1312\n",
      "Epoch 613/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 22.8901 - val_loss: 7.2033\n",
      "Epoch 614/800\n",
      "24/24 [==============================] - 0s 682us/sample - loss: 22.6812 - val_loss: 7.0101\n",
      "Epoch 615/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 30.7359 - val_loss: 7.4067\n",
      "Epoch 616/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 24.8730 - val_loss: 7.7791\n",
      "Epoch 617/800\n",
      "24/24 [==============================] - 0s 646us/sample - loss: 21.0716 - val_loss: 8.0209\n",
      "Epoch 618/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 27.9697 - val_loss: 7.9253\n",
      "Epoch 619/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 20.3328 - val_loss: 8.9556\n",
      "Epoch 620/800\n",
      "24/24 [==============================] - 0s 618us/sample - loss: 25.4591 - val_loss: 9.9964\n",
      "Epoch 621/800\n",
      "24/24 [==============================] - 0s 61us/sample - loss: 26.4205 - val_loss: 10.8752\n",
      "Epoch 622/800\n",
      "24/24 [==============================] - 0s 608us/sample - loss: 21.7013 - val_loss: 11.5635\n",
      "Epoch 623/800\n",
      "24/24 [==============================] - 0s 182us/sample - loss: 22.7468 - val_loss: 11.9952\n",
      "Epoch 624/800\n",
      "24/24 [==============================] - 0s 0s/sample - loss: 25.5954 - val_loss: 12.5583\n",
      "Epoch 625/800\n",
      "24/24 [==============================] - 0s 514us/sample - loss: 31.6973 - val_loss: 12.8981\n",
      "Epoch 626/800\n",
      "24/24 [==============================] - 0s 17ms/sample - loss: 24.0770 - val_loss: 13.7105\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    batch_size=12,\n",
    "    epochs=800,\n",
    "    callbacks = [early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 3.218592405319214\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'val_loss'], dtype='object')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum training loss: 20.33275604248047\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum training loss: {}\".format(history_df['loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 333us/sample - loss: 3.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.218592405319214"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid, batch_size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439.518112</td>\n",
       "      <td>425.496429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439.490112</td>\n",
       "      <td>425.479401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439.461197</td>\n",
       "      <td>425.467438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439.431274</td>\n",
       "      <td>425.442902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439.400253</td>\n",
       "      <td>425.418365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>21.701346</td>\n",
       "      <td>11.563507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>22.746847</td>\n",
       "      <td>11.995239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>25.595397</td>\n",
       "      <td>12.558269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>31.697265</td>\n",
       "      <td>12.898056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>24.076996</td>\n",
       "      <td>13.710521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss    val_loss\n",
       "0    439.518112  425.496429\n",
       "1    439.490112  425.479401\n",
       "2    439.461197  425.467438\n",
       "3    439.431274  425.442902\n",
       "4    439.400253  425.418365\n",
       "..          ...         ...\n",
       "621   21.701346   11.563507\n",
       "622   22.746847   11.995239\n",
       "623   25.595397   12.558269\n",
       "624   31.697265   12.898056\n",
       "625   24.076996   13.710521\n",
       "\n",
       "[626 rows x 2 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df['val_loss'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss        21.775920\n",
       "val_loss     3.218592\n",
       "Name: 605, dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.iloc[605]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
